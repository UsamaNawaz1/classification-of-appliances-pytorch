{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3fb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we don't want the tensor to track the grandient -> mostly we need this in training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19048431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are three options :\n",
    "# x.requires_grad_(False)\n",
    "# x.detach()\n",
    "# with torch.no_grad():\n",
    "    #perform operations\n",
    "\n",
    "    \n",
    "# In training loop -> with each iteration the gradient accumulates and summed up, which is incorrect. In order to remove that you must call grad_zero_() function to make the gradient zero in each iteration after calling the backward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c63936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #1) forward pass -> compute loss\n",
    "#2) calculate the local gradients\n",
    "#3) now do backward pass using chain rule -> dLoss/dWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caca412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch calculates the partial gradients and backward pass automatically for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b111d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step would be t update the weights, next forward and backward ,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0806d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd        # For loading and processing the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import torch.nn.functional as F\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c43008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('Sample_20210716.csv')\n",
    "path = r'D:\\Techlogix\\Predefined_Models' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "df_train = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fe4bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>kW</th>\n",
       "      <th>Load Detected</th>\n",
       "      <th>AC Detected</th>\n",
       "      <th>Motor</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>result</th>\n",
       "      <th>Time</th>\n",
       "      <th>Sr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     kW  Load Detected  AC Detected  Motor  Microwave  result Time  \\\n",
       "0     NaN  1.454              0            0      0          0       0  NaN   \n",
       "1     NaN  1.442              0            0      0          0       0  NaN   \n",
       "2     NaN  1.455              0            0      0          0       0  NaN   \n",
       "3     NaN  1.453              0            0      0          0       0  NaN   \n",
       "4     NaN  1.357              0            0      0          0       0  NaN   \n",
       "\n",
       "   Sr  \n",
       "0 NaN  \n",
       "1 NaN  \n",
       "2 NaN  \n",
       "3 NaN  \n",
       "4 NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d98c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['number','Sr','Time','AC Detected','Motor','Microwave'], axis=1)\n",
    "\n",
    "kW_mean = df_train['kW'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb9e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "kW_std = df_train['kW'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09709367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['kW'] = (df_train['kW'] - kW_mean) / kW_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae5bd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kW</th>\n",
       "      <th>Load Detected</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.649173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.625216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.651169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.647176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.455519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         kW  Load Detected  result\n",
       "0  1.649173              0       0\n",
       "1  1.625216              0       0\n",
       "2  1.651169              0       0\n",
       "3  1.647176              0       0\n",
       "4  1.455519              0       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce8dc35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('result', axis=1).values\n",
    "y_train = df_train['result'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd9f1e0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6543a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.54336211,  1.        ],\n",
       "       [-0.38718454,  0.        ],\n",
       "       [-1.12985606,  0.        ],\n",
       "       ...,\n",
       "       [-0.60878814,  0.        ],\n",
       "       [-0.40714883,  0.        ],\n",
       "       [ 1.37566209,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04b19cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = map(torch.tensor, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69d7fff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9657, 2]) torch.Size([9657])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8281f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(y_hat, y):\n",
    "    \n",
    "#     pred = torch.argmax(y_hat, dim=1)\n",
    "#     return (pred == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc308fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float()\n",
    "y_train = y_train.long()\n",
    "\n",
    "X_test = X_test.float()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "945a2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7e6e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FirstNetwork_v3(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         torch.manual_seed(0)\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(2, 128), \n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 4), \n",
    "#             nn.Softmax()\n",
    "#         )\n",
    "#     def forward(self, X):\n",
    "#         return self.net(X)\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         Y_pred = self.forward(X)\n",
    "#         return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d38fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_v2(x, y, model, opt, loss_fn, epochs = 1000):\n",
    "#     for epoch in range(epochs):\n",
    "#         loss = loss_fn(model(x), y)\n",
    "#         loss.backward()\n",
    "#         opt.step()\n",
    "#         opt.zero_grad()\n",
    "#     return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4de52f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = FirstNetwork_v3()\n",
    "# loss_fn = F.cross_entropy\n",
    "# opt = optim.SGD(fn.parameters(), lr=0.01)\n",
    "\n",
    "# print('Final loss', fit_v2(X_train, y_train, fn, opt, loss_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f34aeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_train = fn.predict(X_train)\n",
    "# #Y_pred_train = np.argmax(Y_pred_train,1)\n",
    "# Y_pred_val = fn.predict(X_test)\n",
    "# #Y_pred_val = np.argmax(Y_pred_val,1)\n",
    "\n",
    "# accuracy_train = accuracy(Y_pred_train, y_train)\n",
    "# accuracy_val = accuracy(Y_pred_val, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f27f25bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training accuracy\", (accuracy_train))\n",
    "# print(\"Validation accuracy\",(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3ec9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device configuration\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5f28e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 100\n",
    "num_classes = 4\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebefb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13ec1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57231002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# will apply softmax for us\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59c19f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 100/9657, loss = 0.3447\n",
      "epoch 1 / 2, step 200/9657, loss = 0.1876\n",
      "epoch 1 / 2, step 300/9657, loss = 0.1497\n",
      "epoch 1 / 2, step 400/9657, loss = 0.1358\n",
      "epoch 1 / 2, step 500/9657, loss = 0.1282\n",
      "epoch 1 / 2, step 600/9657, loss = 0.1230\n",
      "epoch 1 / 2, step 700/9657, loss = 0.1189\n",
      "epoch 1 / 2, step 800/9657, loss = 0.1153\n",
      "epoch 1 / 2, step 900/9657, loss = 0.1120\n",
      "epoch 1 / 2, step 1000/9657, loss = 0.1092\n",
      "epoch 1 / 2, step 1100/9657, loss = 0.1065\n",
      "epoch 1 / 2, step 1200/9657, loss = 0.1042\n",
      "epoch 1 / 2, step 1300/9657, loss = 0.1022\n",
      "epoch 1 / 2, step 1400/9657, loss = 0.1004\n",
      "epoch 1 / 2, step 1500/9657, loss = 0.0988\n",
      "epoch 1 / 2, step 1600/9657, loss = 0.0975\n",
      "epoch 1 / 2, step 1700/9657, loss = 0.0964\n",
      "epoch 1 / 2, step 1800/9657, loss = 0.0954\n",
      "epoch 1 / 2, step 1900/9657, loss = 0.0946\n",
      "epoch 1 / 2, step 2000/9657, loss = 0.0940\n",
      "epoch 1 / 2, step 2100/9657, loss = 0.0934\n",
      "epoch 1 / 2, step 2200/9657, loss = 0.0929\n",
      "epoch 1 / 2, step 2300/9657, loss = 0.0924\n",
      "epoch 1 / 2, step 2400/9657, loss = 0.0920\n",
      "epoch 1 / 2, step 2500/9657, loss = 0.0917\n",
      "epoch 1 / 2, step 2600/9657, loss = 0.0913\n",
      "epoch 1 / 2, step 2700/9657, loss = 0.0910\n",
      "epoch 1 / 2, step 2800/9657, loss = 0.0907\n",
      "epoch 1 / 2, step 2900/9657, loss = 0.0904\n",
      "epoch 1 / 2, step 3000/9657, loss = 0.0902\n",
      "epoch 1 / 2, step 3100/9657, loss = 0.0899\n",
      "epoch 1 / 2, step 3200/9657, loss = 0.0896\n",
      "epoch 1 / 2, step 3300/9657, loss = 0.0894\n",
      "epoch 1 / 2, step 3400/9657, loss = 0.0891\n",
      "epoch 1 / 2, step 3500/9657, loss = 0.0889\n",
      "epoch 1 / 2, step 3600/9657, loss = 0.0887\n",
      "epoch 1 / 2, step 3700/9657, loss = 0.0885\n",
      "epoch 1 / 2, step 3800/9657, loss = 0.0883\n",
      "epoch 1 / 2, step 3900/9657, loss = 0.0881\n",
      "epoch 1 / 2, step 4000/9657, loss = 0.0879\n",
      "epoch 1 / 2, step 4100/9657, loss = 0.0878\n",
      "epoch 1 / 2, step 4200/9657, loss = 0.0876\n",
      "epoch 1 / 2, step 4300/9657, loss = 0.0875\n",
      "epoch 1 / 2, step 4400/9657, loss = 0.0874\n",
      "epoch 1 / 2, step 4500/9657, loss = 0.0873\n",
      "epoch 1 / 2, step 4600/9657, loss = 0.0872\n",
      "epoch 1 / 2, step 4700/9657, loss = 0.0871\n",
      "epoch 1 / 2, step 4800/9657, loss = 0.0870\n",
      "epoch 1 / 2, step 4900/9657, loss = 0.0869\n",
      "epoch 1 / 2, step 5000/9657, loss = 0.0868\n",
      "epoch 1 / 2, step 5100/9657, loss = 0.0867\n",
      "epoch 1 / 2, step 5200/9657, loss = 0.0866\n",
      "epoch 1 / 2, step 5300/9657, loss = 0.0866\n",
      "epoch 1 / 2, step 5400/9657, loss = 0.0865\n",
      "epoch 1 / 2, step 5500/9657, loss = 0.0864\n",
      "epoch 1 / 2, step 5600/9657, loss = 0.0864\n",
      "epoch 1 / 2, step 5700/9657, loss = 0.0863\n",
      "epoch 1 / 2, step 5800/9657, loss = 0.0862\n",
      "epoch 1 / 2, step 5900/9657, loss = 0.0862\n",
      "epoch 1 / 2, step 6000/9657, loss = 0.0861\n",
      "epoch 1 / 2, step 6100/9657, loss = 0.0860\n",
      "epoch 1 / 2, step 6200/9657, loss = 0.0860\n",
      "epoch 1 / 2, step 6300/9657, loss = 0.0859\n",
      "epoch 1 / 2, step 6400/9657, loss = 0.0858\n",
      "epoch 1 / 2, step 6500/9657, loss = 0.0858\n",
      "epoch 1 / 2, step 6600/9657, loss = 0.0857\n",
      "epoch 1 / 2, step 6700/9657, loss = 0.0857\n",
      "epoch 1 / 2, step 6800/9657, loss = 0.0856\n",
      "epoch 1 / 2, step 6900/9657, loss = 0.0855\n",
      "epoch 1 / 2, step 7000/9657, loss = 0.0855\n",
      "epoch 1 / 2, step 7100/9657, loss = 0.0854\n",
      "epoch 1 / 2, step 7200/9657, loss = 0.0853\n",
      "epoch 1 / 2, step 7300/9657, loss = 0.0853\n",
      "epoch 1 / 2, step 7400/9657, loss = 0.0852\n",
      "epoch 1 / 2, step 7500/9657, loss = 0.0851\n",
      "epoch 1 / 2, step 7600/9657, loss = 0.0851\n",
      "epoch 1 / 2, step 7700/9657, loss = 0.0850\n",
      "epoch 1 / 2, step 7800/9657, loss = 0.0849\n",
      "epoch 1 / 2, step 7900/9657, loss = 0.0848\n",
      "epoch 1 / 2, step 8000/9657, loss = 0.0848\n",
      "epoch 1 / 2, step 8100/9657, loss = 0.0847\n",
      "epoch 1 / 2, step 8200/9657, loss = 0.0846\n",
      "epoch 1 / 2, step 8300/9657, loss = 0.0846\n",
      "epoch 1 / 2, step 8400/9657, loss = 0.0845\n",
      "epoch 1 / 2, step 8500/9657, loss = 0.0844\n",
      "epoch 1 / 2, step 8600/9657, loss = 0.0843\n",
      "epoch 1 / 2, step 8700/9657, loss = 0.0843\n",
      "epoch 1 / 2, step 8800/9657, loss = 0.0842\n",
      "epoch 1 / 2, step 8900/9657, loss = 0.0841\n",
      "epoch 1 / 2, step 9000/9657, loss = 0.0840\n",
      "epoch 1 / 2, step 9100/9657, loss = 0.0840\n",
      "epoch 1 / 2, step 9200/9657, loss = 0.0839\n",
      "epoch 1 / 2, step 9300/9657, loss = 0.0838\n",
      "epoch 1 / 2, step 9400/9657, loss = 0.0837\n",
      "epoch 1 / 2, step 9500/9657, loss = 0.0837\n",
      "epoch 1 / 2, step 9600/9657, loss = 0.0836\n",
      "epoch 2 / 2, step 100/9657, loss = 0.0835\n",
      "epoch 2 / 2, step 200/9657, loss = 0.0834\n",
      "epoch 2 / 2, step 300/9657, loss = 0.0834\n",
      "epoch 2 / 2, step 400/9657, loss = 0.0833\n",
      "epoch 2 / 2, step 500/9657, loss = 0.0832\n",
      "epoch 2 / 2, step 600/9657, loss = 0.0832\n",
      "epoch 2 / 2, step 700/9657, loss = 0.0831\n",
      "epoch 2 / 2, step 800/9657, loss = 0.0831\n",
      "epoch 2 / 2, step 900/9657, loss = 0.0830\n",
      "epoch 2 / 2, step 1000/9657, loss = 0.0829\n",
      "epoch 2 / 2, step 1100/9657, loss = 0.0829\n",
      "epoch 2 / 2, step 1200/9657, loss = 0.0828\n",
      "epoch 2 / 2, step 1300/9657, loss = 0.0828\n",
      "epoch 2 / 2, step 1400/9657, loss = 0.0827\n",
      "epoch 2 / 2, step 1500/9657, loss = 0.0827\n",
      "epoch 2 / 2, step 1600/9657, loss = 0.0826\n",
      "epoch 2 / 2, step 1700/9657, loss = 0.0826\n",
      "epoch 2 / 2, step 1800/9657, loss = 0.0826\n",
      "epoch 2 / 2, step 1900/9657, loss = 0.0825\n",
      "epoch 2 / 2, step 2000/9657, loss = 0.0825\n",
      "epoch 2 / 2, step 2100/9657, loss = 0.0825\n",
      "epoch 2 / 2, step 2200/9657, loss = 0.0825\n",
      "epoch 2 / 2, step 2300/9657, loss = 0.0824\n",
      "epoch 2 / 2, step 2400/9657, loss = 0.0824\n",
      "epoch 2 / 2, step 2500/9657, loss = 0.0824\n",
      "epoch 2 / 2, step 2600/9657, loss = 0.0823\n",
      "epoch 2 / 2, step 2700/9657, loss = 0.0823\n",
      "epoch 2 / 2, step 2800/9657, loss = 0.0823\n",
      "epoch 2 / 2, step 2900/9657, loss = 0.0823\n",
      "epoch 2 / 2, step 3000/9657, loss = 0.0822\n",
      "epoch 2 / 2, step 3100/9657, loss = 0.0822\n",
      "epoch 2 / 2, step 3200/9657, loss = 0.0822\n",
      "epoch 2 / 2, step 3300/9657, loss = 0.0822\n",
      "epoch 2 / 2, step 3400/9657, loss = 0.0822\n",
      "epoch 2 / 2, step 3500/9657, loss = 0.0815\n",
      "epoch 2 / 2, step 3600/9657, loss = 0.0811\n",
      "epoch 2 / 2, step 3700/9657, loss = 0.0807\n",
      "epoch 2 / 2, step 3800/9657, loss = 0.0803\n",
      "epoch 2 / 2, step 3900/9657, loss = 0.0799\n",
      "epoch 2 / 2, step 4000/9657, loss = 0.0796\n",
      "epoch 2 / 2, step 4100/9657, loss = 0.0793\n",
      "epoch 2 / 2, step 4200/9657, loss = 0.0791\n",
      "epoch 2 / 2, step 4300/9657, loss = 0.0788\n",
      "epoch 2 / 2, step 4400/9657, loss = 0.0787\n",
      "epoch 2 / 2, step 4500/9657, loss = 0.0785\n",
      "epoch 2 / 2, step 4600/9657, loss = 0.0783\n",
      "epoch 2 / 2, step 4700/9657, loss = 0.0782\n",
      "epoch 2 / 2, step 4800/9657, loss = 0.0781\n",
      "epoch 2 / 2, step 4900/9657, loss = 0.0779\n",
      "epoch 2 / 2, step 5000/9657, loss = 0.0778\n",
      "epoch 2 / 2, step 5100/9657, loss = 0.0777\n",
      "epoch 2 / 2, step 5200/9657, loss = 0.0776\n",
      "epoch 2 / 2, step 5300/9657, loss = 0.0775\n",
      "epoch 2 / 2, step 5400/9657, loss = 0.0775\n",
      "epoch 2 / 2, step 5500/9657, loss = 0.0774\n",
      "epoch 2 / 2, step 5600/9657, loss = 0.0772\n",
      "epoch 2 / 2, step 5700/9657, loss = 0.0771\n",
      "epoch 2 / 2, step 5800/9657, loss = 0.0770\n",
      "epoch 2 / 2, step 5900/9657, loss = 0.0769\n",
      "epoch 2 / 2, step 6000/9657, loss = 0.0768\n",
      "epoch 2 / 2, step 6100/9657, loss = 0.0767\n",
      "epoch 2 / 2, step 6200/9657, loss = 0.0767\n",
      "epoch 2 / 2, step 6300/9657, loss = 0.0766\n",
      "epoch 2 / 2, step 6400/9657, loss = 0.0765\n",
      "epoch 2 / 2, step 6500/9657, loss = 0.0764\n",
      "epoch 2 / 2, step 6600/9657, loss = 0.0763\n",
      "epoch 2 / 2, step 6700/9657, loss = 0.0762\n",
      "epoch 2 / 2, step 6800/9657, loss = 0.0761\n",
      "epoch 2 / 2, step 6900/9657, loss = 0.0760\n",
      "epoch 2 / 2, step 7000/9657, loss = 0.0760\n",
      "epoch 2 / 2, step 7100/9657, loss = 0.0759\n",
      "epoch 2 / 2, step 7200/9657, loss = 0.0758\n",
      "epoch 2 / 2, step 7300/9657, loss = 0.0758\n",
      "epoch 2 / 2, step 7400/9657, loss = 0.0757\n",
      "epoch 2 / 2, step 7500/9657, loss = 0.0756\n",
      "epoch 2 / 2, step 7600/9657, loss = 0.0756\n",
      "epoch 2 / 2, step 7700/9657, loss = 0.0755\n",
      "epoch 2 / 2, step 7800/9657, loss = 0.0755\n",
      "epoch 2 / 2, step 7900/9657, loss = 0.0754\n",
      "epoch 2 / 2, step 8000/9657, loss = 0.0753\n",
      "epoch 2 / 2, step 8100/9657, loss = 0.0753\n",
      "epoch 2 / 2, step 8200/9657, loss = 0.0752\n",
      "epoch 2 / 2, step 8300/9657, loss = 0.0752\n",
      "epoch 2 / 2, step 8400/9657, loss = 0.0751\n",
      "epoch 2 / 2, step 8500/9657, loss = 0.0751\n",
      "epoch 2 / 2, step 8600/9657, loss = 0.0750\n",
      "epoch 2 / 2, step 8700/9657, loss = 0.0750\n",
      "epoch 2 / 2, step 8800/9657, loss = 0.0750\n",
      "epoch 2 / 2, step 8900/9657, loss = 0.0749\n",
      "epoch 2 / 2, step 9000/9657, loss = 0.0749\n",
      "epoch 2 / 2, step 9100/9657, loss = 0.0748\n",
      "epoch 2 / 2, step 9200/9657, loss = 0.0748\n",
      "epoch 2 / 2, step 9300/9657, loss = 0.0748\n",
      "epoch 2 / 2, step 9400/9657, loss = 0.0747\n",
      "epoch 2 / 2, step 9500/9657, loss = 0.0747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 / 2, step 9600/9657, loss = 0.0746\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "\n",
    "n_total_steps = len(X_train)\n",
    "for epoch in range(num_epochs):\n",
    "     for i, data in enumerate(X_train):\n",
    "            labels = y_train.to(device)\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #to empty the value\n",
    "            loss.backward()\n",
    "            #do backpropogation\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e923fcdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Tensor' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-876bc279d091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_of_classes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Tensor' and 'tuple'"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    list_of_classes = [0,1,2,3]\n",
    "    overall_acc = [0 for c in list_of_classes]\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_ac_accurrate = 0\n",
    "    for data in X_test:\n",
    "        labels = y_test.to(device)\n",
    "        outputs = model(X_test)\n",
    "        #value and index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        for c in list_of_classes:\n",
    "            acc[c] = ((predictions == labels) * (labels == c)).float() / (max(labels == c).sum(), 1)\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples \n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd75fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
